{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alphabet Soup Charity Analysis - OptimizationÂ¶\n",
    "## Compare the performance of the NN model to the Logit, SVM and RF models\n",
    "### Preprocess the data based on earlier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flasu\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:48: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"charity_data.csv\")\n",
    "application_df = application_df.drop(['EIN', 'NAME'], axis=1)\n",
    "\n",
    "\n",
    "# Create bins for rare occurrences in columns\n",
    "# Application Type\n",
    "apptype_counts = application_df.APPLICATION_TYPE.value_counts()\n",
    "replace_application = list(apptype_counts[apptype_counts < 500].index)\n",
    "for app in replace_application:\n",
    "    application_df.APPLICATION_TYPE = application_df.APPLICATION_TYPE.replace(app,\"Other\")\n",
    "\n",
    "# Classification\n",
    "classify_counts = application_df.CLASSIFICATION.value_counts()\n",
    "replace_class = list(classify_counts[classify_counts < 1880].index)\n",
    "for cls in replace_class:\n",
    "    application_df.CLASSIFICATION = application_df.CLASSIFICATION.replace(cls,\"Other\")\n",
    "\n",
    "\n",
    "# Generate our categorical variable lists\n",
    "application_cat = application_df.dtypes[application_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "\n",
    "# Use OHE to prepare data for analysis\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(application_df[application_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(application_cat)\n",
    "encode_df.head()\n",
    "\n",
    "# Merge one-hot encoded features and drop the originals\n",
    "application_df = application_df.merge(encode_df,left_index=True, right_index=True)\n",
    "application_df = application_df.drop(application_cat,1)\n",
    "\n",
    "\n",
    "# Split our preprocessed data into our features and target arrays\n",
    "#y = application_df[\"IS_SUCCESSFUL\"].values\n",
    "#X = application_df.drop([\"IS_SUCCESSFUL\"],1).values\n",
    "X = application_df.drop(\"IS_SUCCESSFUL\", axis=1)\n",
    "y = application_df[\"IS_SUCCESSFUL\"]\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression model accuracy: 0.466\n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "log_classifier = LogisticRegression(solver=\"lbfgs\",max_iter=200)\n",
    "\n",
    "# Train the model\n",
    "log_classifier.fit(X_train_scaled,y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = log_classifier.predict(X_test)\n",
    "print(f\" Logistic regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support-Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM model accuracy: 0.722\n"
     ]
    }
   ],
   "source": [
    "# Create the SVM model\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Train the model\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "print(f\" SVM model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random forest predictive accuracy: 0.714\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Model Accuracy\n",
    "\n",
    "| Model    | Accuracy |\n",
    "|----------|----------|\n",
    "| NN       |  0.73    |\n",
    "| Logit    |  0.46    |\n",
    "| SVM      |  0.72    |\n",
    "| RF       |  0.71    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evidence of similar performance for all except Logit model. </br> Consider feature reduction and other changes to optimize NN model.\n",
    "Due to difficulty in determining feature importance using neural networks, review is based on random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance in the original neural network model\n",
    "feature_importances = rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('USE_CASE_Other', 5.998670713090662e-05),\n",
       " ('AFFILIATION_Other', 7.922401334982439e-05),\n",
       " ('STATUS', 0.00019187529907672935),\n",
       " ('AFFILIATION_Regional', 0.00027046776542260614),\n",
       " ('ORGANIZATION_Corporation', 0.000440347530726473),\n",
       " ('SPECIAL_CONSIDERATIONS_N', 0.00047905932685652556),\n",
       " ('SPECIAL_CONSIDERATIONS_Y', 0.000565831397444202),\n",
       " ('AFFILIATION_National', 0.0005950601451037992),\n",
       " ('AFFILIATION_Family/Parent', 0.0012450414050965413),\n",
       " ('USE_CASE_Heathcare', 0.00132488682209223),\n",
       " ('INCOME_AMT_50M+', 0.0018870300072749112),\n",
       " ('APPLICATION_TYPE_Other', 0.00200787060912953),\n",
       " ('INCOME_AMT_5M-10M', 0.0023972628671981373),\n",
       " ('INCOME_AMT_10M-50M', 0.0027663595567476358),\n",
       " ('ORGANIZATION_Co-operative', 0.003076972694199374),\n",
       " ('INCOME_AMT_10000-24999', 0.003530476061946203),\n",
       " ('USE_CASE_CommunityServ', 0.0038208617481205087),\n",
       " ('APPLICATION_TYPE_T8', 0.004373322691349571),\n",
       " ('APPLICATION_TYPE_T7', 0.004866307915710914),\n",
       " ('INCOME_AMT_1-9999', 0.006102090930913049),\n",
       " ('INCOME_AMT_100000-499999', 0.006226697285410235),\n",
       " ('INCOME_AMT_1M-5M', 0.006781002738897716),\n",
       " ('INCOME_AMT_25000-99999', 0.00733429119020774),\n",
       " ('CLASSIFICATION_C3000', 0.008447883955056896),\n",
       " ('CLASSIFICATION_C1200', 0.008910877722619743),\n",
       " ('INCOME_AMT_0', 0.00942137761793198),\n",
       " ('USE_CASE_Preservation', 0.010605008172756798),\n",
       " ('USE_CASE_ProductDev', 0.011354242144554657),\n",
       " ('APPLICATION_TYPE_T6', 0.011831452273032835),\n",
       " ('APPLICATION_TYPE_T3', 0.014181890246098613),\n",
       " ('CLASSIFICATION_C1000', 0.014312651137176169),\n",
       " ('APPLICATION_TYPE_T19', 0.0164544666392715),\n",
       " ('APPLICATION_TYPE_T4', 0.01812690711470839),\n",
       " ('CLASSIFICATION_C2000', 0.018452086165628108),\n",
       " ('CLASSIFICATION_Other', 0.0195390356327476),\n",
       " ('CLASSIFICATION_C2100', 0.019958491978765244),\n",
       " ('ORGANIZATION_Trust', 0.02073163392442216),\n",
       " ('APPLICATION_TYPE_T10', 0.02494104416060051),\n",
       " ('ORGANIZATION_Association', 0.026764157972363672),\n",
       " ('APPLICATION_TYPE_T5', 0.027955563962022683),\n",
       " ('AFFILIATION_Independent', 0.12471554632312969),\n",
       " ('AFFILIATION_CompanySponsored', 0.13385290629046417),\n",
       " ('ASK_AMT', 0.39902044985724333)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = sorted(zip(X.columns, feature_importances), key = lambda x: x[1])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Attempt #1: Adjust Features\n",
    "### Create dataset for optimization\n",
    "##### In addition to dropping EIN and NAME, the following modifications were made:\n",
    "* Dropped features include STATUS and SPECIAL CONSIDERATION, based on having <0.02 contribution to feature importance as defined by RF model.\n",
    "* Bins were created for AFFILIATION and INCOME_AMT based on rare occurrences in columns (analysis steps not shown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flasu\\anaconda3\\envs\\PythonData\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:55: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "C:\\Users\\flasu\\anaconda3\\envs\\PythonData\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:60: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"charity_data.csv\")\n",
    "application_df = application_df.drop(['EIN', 'NAME', 'STATUS', 'SPECIAL_CONSIDERATIONS'], axis=1)\n",
    "\n",
    "\n",
    "# Create bins for rare occurrences in columns\n",
    "# Application Type\n",
    "apptype_counts = application_df.APPLICATION_TYPE.value_counts()\n",
    "replace_application = list(apptype_counts[apptype_counts < 500].index)\n",
    "for app in replace_application:\n",
    "    application_df.APPLICATION_TYPE = application_df.APPLICATION_TYPE.replace(app,\"Other\")\n",
    "\n",
    "# Classification\n",
    "classify_counts = application_df.CLASSIFICATION.value_counts()\n",
    "replace_class = list(classify_counts[classify_counts < 1880].index)\n",
    "for cls in replace_class:\n",
    "    application_df.CLASSIFICATION = application_df.CLASSIFICATION.replace(cls,\"Other\")\n",
    "\n",
    "# Affiliation (review not shown)\n",
    "afilly_counts = application_df.AFFILIATION.value_counts()\n",
    "replace_affiliation = list(afilly_counts[afilly_counts <15000].index)\n",
    "for filly in replace_affiliation:\n",
    "    application_df.AFFILIATION = application_df.AFFILIATION.replace(filly,\"Other\")\n",
    "\n",
    "# Income Amount\n",
    "income_counts = application_df.INCOME_AMT.value_counts()\n",
    "replace_income = list(income_counts[income_counts >0].index)\n",
    "for income in income_counts:\n",
    "    application_df.INCOME_AMT = application_df.INCOME_AMT.replace(income,\"Other\")\n",
    "\n",
    "\n",
    "# Generate our categorical variable lists\n",
    "application_cat = application_df.dtypes[application_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "\n",
    "# Use OHE to prepare data for analysis\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(application_df[application_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(application_cat)\n",
    "encode_df.head()\n",
    "\n",
    "# Merge one-hot encoded features and drop the originals\n",
    "application_df = application_df.merge(encode_df,left_index=True, right_index=True)\n",
    "application_df = application_df.drop(application_cat,1)\n",
    "\n",
    "\n",
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df[\"IS_SUCCESSFUL\"].values\n",
    "X = application_df.drop([\"IS_SUCCESSFUL\"],1).values\n",
    "#X = application_df.drop(\"IS_SUCCESSFUL\", axis=1)\n",
    "#y = application_df[\"IS_SUCCESSFUL\"]\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the same NN model now that features have been modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\"\n",
    "\n",
    "# Create a callback that saves the model's weights every epoch\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    period=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 304       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 45        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 8\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn_features = tf.keras.models.Sequential()\n",
    "# First hidden layer\n",
    "nn_features.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Second hidden layer\n",
    "nn_features.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn_features.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "# Check the structure of the model\n",
    "nn_features.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 840us/step - loss: 0.6226 - accuracy: 0.6814\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 961us/step - loss: 0.5813 - accuracy: 0.7184\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5643 - accuracy: 0.7266\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5576 - accuracy: 0.7292\n",
      "Epoch 5/100\n",
      "778/804 [============================>.] - ETA: 0s - loss: 0.5558 - accuracy: 0.7307\n",
      "Epoch 5: saving model to checkpoints\\weights.05.hdf5\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5561 - accuracy: 0.7305\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 991us/step - loss: 0.5550 - accuracy: 0.7296\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5542 - accuracy: 0.7296\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5536 - accuracy: 0.7308\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 924us/step - loss: 0.5530 - accuracy: 0.7302\n",
      "Epoch 10/100\n",
      "790/804 [============================>.] - ETA: 0s - loss: 0.5533 - accuracy: 0.7302\n",
      "Epoch 10: saving model to checkpoints\\weights.10.hdf5\n",
      "804/804 [==============================] - 1s 843us/step - loss: 0.5527 - accuracy: 0.7304\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 937us/step - loss: 0.5524 - accuracy: 0.7306\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 811us/step - loss: 0.5517 - accuracy: 0.7315\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 920us/step - loss: 0.5516 - accuracy: 0.7316\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5514 - accuracy: 0.7316\n",
      "Epoch 15/100\n",
      "801/804 [============================>.] - ETA: 0s - loss: 0.5507 - accuracy: 0.7306\n",
      "Epoch 15: saving model to checkpoints\\weights.15.hdf5\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5510 - accuracy: 0.7305\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5506 - accuracy: 0.7326\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5505 - accuracy: 0.7317\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5502 - accuracy: 0.7334\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5499 - accuracy: 0.7325\n",
      "Epoch 20/100\n",
      "783/804 [============================>.] - ETA: 0s - loss: 0.5497 - accuracy: 0.7332\n",
      "Epoch 20: saving model to checkpoints\\weights.20.hdf5\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5496 - accuracy: 0.7332\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5493 - accuracy: 0.7333\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5490 - accuracy: 0.7333\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5490 - accuracy: 0.7331\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5488 - accuracy: 0.7318\n",
      "Epoch 25/100\n",
      "783/804 [============================>.] - ETA: 0s - loss: 0.5483 - accuracy: 0.7340\n",
      "Epoch 25: saving model to checkpoints\\weights.25.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.7338\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5483 - accuracy: 0.7336\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7332\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5478 - accuracy: 0.7338\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5477 - accuracy: 0.7336\n",
      "Epoch 30/100\n",
      "786/804 [============================>.] - ETA: 0s - loss: 0.5474 - accuracy: 0.7334\n",
      "Epoch 30: saving model to checkpoints\\weights.30.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5475 - accuracy: 0.7332\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5473 - accuracy: 0.7338\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5474 - accuracy: 0.7324\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5472 - accuracy: 0.7335\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7322\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.7343\n",
      "Epoch 35: saving model to checkpoints\\weights.35.hdf5\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7343\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7347\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7344\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7332\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7341\n",
      "Epoch 40/100\n",
      "782/804 [============================>.] - ETA: 0s - loss: 0.5455 - accuracy: 0.7350\n",
      "Epoch 40: saving model to checkpoints\\weights.40.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7344\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7334\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5460 - accuracy: 0.7343\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5459 - accuracy: 0.7335\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5459 - accuracy: 0.7334\n",
      "Epoch 45/100\n",
      "800/804 [============================>.] - ETA: 0s - loss: 0.5456 - accuracy: 0.7332\n",
      "Epoch 45: saving model to checkpoints\\weights.45.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7329\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7341\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7342\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7331\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7350\n",
      "Epoch 50/100\n",
      "785/804 [============================>.] - ETA: 0s - loss: 0.5455 - accuracy: 0.7335\n",
      "Epoch 50: saving model to checkpoints\\weights.50.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7334\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7336\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7340\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7329\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7338\n",
      "Epoch 55/100\n",
      "802/804 [============================>.] - ETA: 0s - loss: 0.5455 - accuracy: 0.7338\n",
      "Epoch 55: saving model to checkpoints\\weights.55.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7338\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7334\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7348\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7334\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7345\n",
      "Epoch 60/100\n",
      "799/804 [============================>.] - ETA: 0s - loss: 0.5457 - accuracy: 0.7344\n",
      "Epoch 60: saving model to checkpoints\\weights.60.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7345\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7340\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7341\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7343\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7353\n",
      "Epoch 65/100\n",
      "782/804 [============================>.] - ETA: 0s - loss: 0.5453 - accuracy: 0.7347\n",
      "Epoch 65: saving model to checkpoints\\weights.65.hdf5\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7347\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7343\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7346\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7347\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7337\n",
      "Epoch 70/100\n",
      "791/804 [============================>.] - ETA: 0s - loss: 0.5446 - accuracy: 0.7342\n",
      "Epoch 70: saving model to checkpoints\\weights.70.hdf5\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7339\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7346\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7355\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7346\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7348\n",
      "Epoch 75/100\n",
      "770/804 [===========================>..] - ETA: 0s - loss: 0.5444 - accuracy: 0.7341\n",
      "Epoch 75: saving model to checkpoints\\weights.75.hdf5\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7339\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7343\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7343\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7353\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7340\n",
      "Epoch 80/100\n",
      "792/804 [============================>.] - ETA: 0s - loss: 0.5449 - accuracy: 0.7342\n",
      "Epoch 80: saving model to checkpoints\\weights.80.hdf5\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7345\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7343\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7353\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7352\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7341\n",
      "Epoch 85/100\n",
      "792/804 [============================>.] - ETA: 0s - loss: 0.5444 - accuracy: 0.7349\n",
      "Epoch 85: saving model to checkpoints\\weights.85.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7348\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7343\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7346\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7345\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7343\n",
      "Epoch 90/100\n",
      "779/804 [============================>.] - ETA: 0s - loss: 0.5446 - accuracy: 0.7345\n",
      "Epoch 90: saving model to checkpoints\\weights.90.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7348\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7343\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7346\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7339\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7339\n",
      "Epoch 95/100\n",
      "779/804 [============================>.] - ETA: 0s - loss: 0.5437 - accuracy: 0.7346\n",
      "Epoch 95: saving model to checkpoints\\weights.95.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7343\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7343\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7348\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7346\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7348\n",
      "Epoch 100/100\n",
      "800/804 [============================>.] - ETA: 0s - loss: 0.5442 - accuracy: 0.7345\n",
      "Epoch 100: saving model to checkpoints\\weights.100.hdf5\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7347\n",
      "268/268 - 0s - loss: 0.5562 - accuracy: 0.7272 - 330ms/epoch - 1ms/step\n",
      "Loss: 0.5562235713005066, Accuracy: 0.7272303104400635\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn_features.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_features.fit(X_train_scaled,y_train,epochs=100,callbacks=[cp_callback])\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_features.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of 73%; adjusting features did not optimize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn_features.save(\"AlphabetSoupCharity_featureAdj.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Attempt 2: Add More Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 8)                 304       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 45        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                60        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 420\n",
      "Trainable params: 420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.6099 - accuracy: 0.6764\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5663 - accuracy: 0.7219\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 946us/step - loss: 0.5575 - accuracy: 0.7283\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5555 - accuracy: 0.7284\n",
      "Epoch 5/100\n",
      "782/804 [============================>.] - ETA: 0s - loss: 0.5550 - accuracy: 0.7275\n",
      "Epoch 5: saving model to checkpoints\\weights.05.hdf5\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5546 - accuracy: 0.7281\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5538 - accuracy: 0.7287\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5530 - accuracy: 0.7299\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5528 - accuracy: 0.7285\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7306\n",
      "Epoch 10/100\n",
      "785/804 [============================>.] - ETA: 0s - loss: 0.5514 - accuracy: 0.7298\n",
      "Epoch 10: saving model to checkpoints\\weights.10.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5519 - accuracy: 0.7295\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5514 - accuracy: 0.7309\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5511 - accuracy: 0.7304\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5506 - accuracy: 0.7307\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5505 - accuracy: 0.7311\n",
      "Epoch 15/100\n",
      "783/804 [============================>.] - ETA: 0s - loss: 0.5503 - accuracy: 0.7309\n",
      "Epoch 15: saving model to checkpoints\\weights.15.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5505 - accuracy: 0.7309\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5502 - accuracy: 0.7310\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5498 - accuracy: 0.7309\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5497 - accuracy: 0.7310\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5494 - accuracy: 0.7321\n",
      "Epoch 20/100\n",
      "794/804 [============================>.] - ETA: 0s - loss: 0.5488 - accuracy: 0.7330\n",
      "Epoch 20: saving model to checkpoints\\weights.20.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5492 - accuracy: 0.7329\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5492 - accuracy: 0.7323\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5492 - accuracy: 0.7326\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5491 - accuracy: 0.7322\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5486 - accuracy: 0.7329\n",
      "Epoch 25/100\n",
      "771/804 [===========================>..] - ETA: 0s - loss: 0.5474 - accuracy: 0.7328\n",
      "Epoch 25: saving model to checkpoints\\weights.25.hdf5\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.7318\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5483 - accuracy: 0.7317\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5483 - accuracy: 0.7323\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7321\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7325\n",
      "Epoch 30/100\n",
      "788/804 [============================>.] - ETA: 0s - loss: 0.5465 - accuracy: 0.7334\n",
      "Epoch 30: saving model to checkpoints\\weights.30.hdf5\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7325\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5480 - accuracy: 0.7331\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.7320\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5475 - accuracy: 0.7334\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5473 - accuracy: 0.7331\n",
      "Epoch 35/100\n",
      "765/804 [===========================>..] - ETA: 0s - loss: 0.5463 - accuracy: 0.7328\n",
      "Epoch 35: saving model to checkpoints\\weights.35.hdf5\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5473 - accuracy: 0.7326\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5470 - accuracy: 0.7324\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5472 - accuracy: 0.7327\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5473 - accuracy: 0.7324\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5468 - accuracy: 0.7338\n",
      "Epoch 40/100\n",
      "786/804 [============================>.] - ETA: 0s - loss: 0.5470 - accuracy: 0.7333\n",
      "Epoch 40: saving model to checkpoints\\weights.40.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7332\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7338\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7336\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7334\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7332\n",
      "Epoch 45/100\n",
      "779/804 [============================>.] - ETA: 0s - loss: 0.5466 - accuracy: 0.7333\n",
      "Epoch 45: saving model to checkpoints\\weights.45.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7332\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7320\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5463 - accuracy: 0.7338\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7332\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7330\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5463 - accuracy: 0.7328\n",
      "Epoch 50: saving model to checkpoints\\weights.50.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7328\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7335\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7337\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7332\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7331\n",
      "Epoch 55/100\n",
      "783/804 [============================>.] - ETA: 0s - loss: 0.5456 - accuracy: 0.7329\n",
      "Epoch 55: saving model to checkpoints\\weights.55.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7327\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7324\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7348\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7338\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7332\n",
      "Epoch 60/100\n",
      "772/804 [===========================>..] - ETA: 0s - loss: 0.5459 - accuracy: 0.7329\n",
      "Epoch 60: saving model to checkpoints\\weights.60.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7328\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7328\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7341\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7329\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7336\n",
      "Epoch 65/100\n",
      "800/804 [============================>.] - ETA: 0s - loss: 0.5458 - accuracy: 0.7318\n",
      "Epoch 65: saving model to checkpoints\\weights.65.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7320\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7331\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7332\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7332\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7333\n",
      "Epoch 70/100\n",
      "798/804 [============================>.] - ETA: 0s - loss: 0.5444 - accuracy: 0.7346\n",
      "Epoch 70: saving model to checkpoints\\weights.70.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7341\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7327\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7337\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7339\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7342\n",
      "Epoch 75/100\n",
      "775/804 [===========================>..] - ETA: 0s - loss: 0.5459 - accuracy: 0.7332\n",
      "Epoch 75: saving model to checkpoints\\weights.75.hdf5\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7341\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7342\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7345\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7349\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7337\n",
      "Epoch 80/100\n",
      "782/804 [============================>.] - ETA: 0s - loss: 0.5447 - accuracy: 0.7332\n",
      "Epoch 80: saving model to checkpoints\\weights.80.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7335\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7341\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7338\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7343\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7333\n",
      "Epoch 85/100\n",
      "801/804 [============================>.] - ETA: 0s - loss: 0.5443 - accuracy: 0.7343\n",
      "Epoch 85: saving model to checkpoints\\weights.85.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7341\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7327\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7344\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7330\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7343\n",
      "Epoch 90/100\n",
      "778/804 [============================>.] - ETA: 0s - loss: 0.5437 - accuracy: 0.7347\n",
      "Epoch 90: saving model to checkpoints\\weights.90.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7344\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7346\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7341\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7342\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7343\n",
      "Epoch 95/100\n",
      "788/804 [============================>.] - ETA: 0s - loss: 0.5447 - accuracy: 0.7339\n",
      "Epoch 95: saving model to checkpoints\\weights.95.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7343\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7332\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7336\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7339\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7353\n",
      "Epoch 100/100\n",
      "793/804 [============================>.] - ETA: 0s - loss: 0.5439 - accuracy: 0.7349\n",
      "Epoch 100: saving model to checkpoints\\weights.100.hdf5\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7352\n",
      "268/268 - 1s - loss: 0.5538 - accuracy: 0.7248 - 513ms/epoch - 2ms/step\n",
      "Loss: 0.5538111329078674, Accuracy: 0.724781334400177\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 8\n",
    "hidden_nodes_layer2 = 5\n",
    "hidden_nodes_layer3 = 10\n",
    "\n",
    "nn_layers = tf.keras.models.Sequential()\n",
    "nn_layers.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "nn_layers.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn_layers.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "nn_layers.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "nn_layers.summary()\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_layers.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_layers.fit(X_train_scaled,y_train,epochs=100,callbacks=[cp_callback])\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_layers.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of 72%; adding a hidden layer did not optimize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn_layers.save(\"AlphabetSoupCharity_layerAdj.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Attempt 3: Increasing the Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 8)                 304       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 45        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "804/804 [==============================] - 1s 898us/step - loss: 0.6304 - accuracy: 0.6880\n",
      "Epoch 2/150\n",
      "804/804 [==============================] - 1s 829us/step - loss: 0.5734 - accuracy: 0.7257\n",
      "Epoch 3/150\n",
      "804/804 [==============================] - 1s 941us/step - loss: 0.5605 - accuracy: 0.7267\n",
      "Epoch 4/150\n",
      "804/804 [==============================] - 1s 861us/step - loss: 0.5581 - accuracy: 0.7269\n",
      "Epoch 5/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5564 - accuracy: 0.7288\n",
      "Epoch 6/150\n",
      "804/804 [==============================] - 1s 857us/step - loss: 0.5550 - accuracy: 0.7296\n",
      "Epoch 7/150\n",
      "804/804 [==============================] - 1s 994us/step - loss: 0.5535 - accuracy: 0.7288\n",
      "Epoch 8/150\n",
      "804/804 [==============================] - 1s 866us/step - loss: 0.5532 - accuracy: 0.7285\n",
      "Epoch 9/150\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5521 - accuracy: 0.7294\n",
      "Epoch 10/150\n",
      "804/804 [==============================] - 1s 931us/step - loss: 0.5514 - accuracy: 0.7303\n",
      "Epoch 11/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5508 - accuracy: 0.7302\n",
      "Epoch 12/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5504 - accuracy: 0.7303\n",
      "Epoch 13/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5501 - accuracy: 0.7311\n",
      "Epoch 14/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5496 - accuracy: 0.7308\n",
      "Epoch 15/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5495 - accuracy: 0.7315\n",
      "Epoch 16/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5493 - accuracy: 0.7315\n",
      "Epoch 17/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5489 - accuracy: 0.7322\n",
      "Epoch 18/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5485 - accuracy: 0.7320\n",
      "Epoch 19/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5486 - accuracy: 0.7323\n",
      "Epoch 20/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5486 - accuracy: 0.7308\n",
      "Epoch 21/150\n",
      "804/804 [==============================] - 1s 993us/step - loss: 0.5482 - accuracy: 0.7321\n",
      "Epoch 22/150\n",
      "804/804 [==============================] - 1s 996us/step - loss: 0.5480 - accuracy: 0.7321\n",
      "Epoch 23/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7317\n",
      "Epoch 24/150\n",
      "804/804 [==============================] - 1s 945us/step - loss: 0.5479 - accuracy: 0.7320\n",
      "Epoch 25/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5479 - accuracy: 0.7315\n",
      "Epoch 26/150\n",
      "804/804 [==============================] - 1s 948us/step - loss: 0.5477 - accuracy: 0.7317\n",
      "Epoch 27/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.7317\n",
      "Epoch 28/150\n",
      "804/804 [==============================] - 1s 942us/step - loss: 0.5474 - accuracy: 0.7318\n",
      "Epoch 29/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7325\n",
      "Epoch 30/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5472 - accuracy: 0.7326\n",
      "Epoch 31/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5473 - accuracy: 0.7317\n",
      "Epoch 32/150\n",
      "804/804 [==============================] - 1s 952us/step - loss: 0.5470 - accuracy: 0.7322\n",
      "Epoch 33/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5468 - accuracy: 0.7325\n",
      "Epoch 34/150\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5472 - accuracy: 0.7317\n",
      "Epoch 35/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5470 - accuracy: 0.7324\n",
      "Epoch 36/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5470 - accuracy: 0.7320\n",
      "Epoch 37/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5464 - accuracy: 0.7311\n",
      "Epoch 38/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7325\n",
      "Epoch 39/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.7323\n",
      "Epoch 40/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5463 - accuracy: 0.7331\n",
      "Epoch 41/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5464 - accuracy: 0.7328\n",
      "Epoch 42/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5461 - accuracy: 0.7320\n",
      "Epoch 43/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5460 - accuracy: 0.7314\n",
      "Epoch 44/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7309\n",
      "Epoch 45/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7323\n",
      "Epoch 46/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7324\n",
      "Epoch 47/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7330\n",
      "Epoch 48/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7331\n",
      "Epoch 49/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7333\n",
      "Epoch 50/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7334\n",
      "Epoch 51/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7327\n",
      "Epoch 52/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7339\n",
      "Epoch 53/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7330\n",
      "Epoch 54/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7345\n",
      "Epoch 55/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7323\n",
      "Epoch 56/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7339\n",
      "Epoch 57/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7335\n",
      "Epoch 58/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7338\n",
      "Epoch 59/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7333\n",
      "Epoch 60/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7336\n",
      "Epoch 61/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7341\n",
      "Epoch 62/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7338\n",
      "Epoch 63/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7338\n",
      "Epoch 64/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7333\n",
      "Epoch 65/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7336\n",
      "Epoch 66/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7338\n",
      "Epoch 67/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7341\n",
      "Epoch 68/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7348\n",
      "Epoch 69/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7335\n",
      "Epoch 70/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7331\n",
      "Epoch 71/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7342\n",
      "Epoch 72/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7343\n",
      "Epoch 73/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7353\n",
      "Epoch 74/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7340\n",
      "Epoch 75/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7345\n",
      "Epoch 76/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7341\n",
      "Epoch 77/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7341\n",
      "Epoch 78/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7343\n",
      "Epoch 79/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7348\n",
      "Epoch 80/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7341\n",
      "Epoch 81/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7347\n",
      "Epoch 82/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7347\n",
      "Epoch 83/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7346\n",
      "Epoch 84/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5439 - accuracy: 0.7352\n",
      "Epoch 85/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7332\n",
      "Epoch 86/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7346\n",
      "Epoch 87/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7343\n",
      "Epoch 88/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7336\n",
      "Epoch 89/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7340\n",
      "Epoch 90/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7343\n",
      "Epoch 91/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5439 - accuracy: 0.7337\n",
      "Epoch 92/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7340\n",
      "Epoch 93/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7341\n",
      "Epoch 94/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7339\n",
      "Epoch 95/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7341\n",
      "Epoch 96/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7339\n",
      "Epoch 97/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7342\n",
      "Epoch 98/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7354\n",
      "Epoch 99/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7348\n",
      "Epoch 100/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7335\n",
      "Epoch 101/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7344\n",
      "Epoch 102/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.7341\n",
      "Epoch 103/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5432 - accuracy: 0.7348\n",
      "Epoch 104/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.7351\n",
      "Epoch 105/150\n",
      "804/804 [==============================] - 1s 960us/step - loss: 0.5434 - accuracy: 0.7334\n",
      "Epoch 106/150\n",
      "804/804 [==============================] - 1s 953us/step - loss: 0.5434 - accuracy: 0.7353\n",
      "Epoch 107/150\n",
      "804/804 [==============================] - 1s 991us/step - loss: 0.5436 - accuracy: 0.7339\n",
      "Epoch 108/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7354\n",
      "Epoch 109/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7338\n",
      "Epoch 110/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7351\n",
      "Epoch 111/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7353\n",
      "Epoch 112/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7351\n",
      "Epoch 113/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7351\n",
      "Epoch 114/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7336\n",
      "Epoch 115/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7348\n",
      "Epoch 116/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7337\n",
      "Epoch 117/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7348\n",
      "Epoch 118/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7352\n",
      "Epoch 119/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7351\n",
      "Epoch 120/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7345\n",
      "Epoch 121/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7339\n",
      "Epoch 122/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7355\n",
      "Epoch 123/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7341\n",
      "Epoch 124/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7345\n",
      "Epoch 125/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7337\n",
      "Epoch 126/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7351\n",
      "Epoch 127/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7353\n",
      "Epoch 128/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7361\n",
      "Epoch 129/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7348\n",
      "Epoch 130/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7359\n",
      "Epoch 131/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7345\n",
      "Epoch 132/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7352\n",
      "Epoch 133/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7353\n",
      "Epoch 134/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7346\n",
      "Epoch 135/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7347\n",
      "Epoch 136/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7342\n",
      "Epoch 137/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7350\n",
      "Epoch 138/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7350\n",
      "Epoch 139/150\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7345\n",
      "Epoch 140/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7355\n",
      "Epoch 141/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7341\n",
      "Epoch 142/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7347\n",
      "Epoch 143/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7342\n",
      "Epoch 144/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7347\n",
      "Epoch 145/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7336\n",
      "Epoch 146/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7340\n",
      "Epoch 147/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7351\n",
      "Epoch 148/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7348\n",
      "Epoch 149/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7345\n",
      "Epoch 150/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7339\n",
      "268/268 - 1s - loss: 0.5528 - accuracy: 0.7328 - 628ms/epoch - 2ms/step\n",
      "Loss: 0.5528357028961182, Accuracy: 0.7328279614448547\n"
     ]
    }
   ],
   "source": [
    "## Adding a hidden layer did not improve model performance.\n",
    "\n",
    "### Optimization Attempt 3: Increase the number of epochs\n",
    "\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 8\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "# Define the basic neural network model\n",
    "nn_epochs = tf.keras.models.Sequential()\n",
    "nn_epochs.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "nn_epochs.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn_epochs.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "nn_epochs.summary()\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_epochs.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_epochs.fit(X_train_scaled, y_train, epochs=150)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_epochs.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of 73%; increasing the number of epochs did not optimize model peformance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to HDF5 file\n",
    "nn_epochs.save(\"AlphabetSoupCharity_epochsAdj.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION: When comparing NN, RF and SVM performance on this dataset, RF is the preferred model as similar accuracy is achieved in the shortest amount of time. Additional steps should be taken to see if accuracy can be further improved using the RF model."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b82152eb230bdc74c81ffc06bb057fc1aa2a20fc1763b2fe2e4b13e0c8e47bbd"
  },
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
